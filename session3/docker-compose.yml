version: '3.8'
services:
  train:
    build:
      context: ./
      dockerfile: Dockerfile.train
    volumes:
      - mnist:/workspace/mnist
      # - ./mnist/model:/workspace/mnist/model
      # - ./mnist/data:/workspace/mnist/data
      # - mnist/model:/workspace/mnist/model
      # - mnist/data:/workspace/mnist/data
    restart: on-failure
    command: python train.py --resume
    # command: python train.py add cli args here as to where the model is supposed to be stored

  evaluate:
    build:
      context: ./
      dockerfile: Dockerfile.eval

    #Mount volumes
    volumes:
      - mnist:/workspace/mnist
      # - ./mnist/data:/workspace/mnist/data
      # - ./mnist/model:/workspace/mnist/model
      # - mnist/data:/workspace/mnist/data
      # - mnist/model:/workspace/mnist/model
    command: python eval.py
    #also mount the mnist volume

    # Run the evaluation command
    # command: python eval.py maybe add command line argument here, like where the model is located

  infer:
    build:
      context: ./
      dockerfile: Dockerfile.infer

    #Mount volumes
    volumes:
      - mnist:/workspace/mnist
      # - mnist/data:/workspace/mnist/data
      # - mnist/model:/workspace/mnist/model
      # - mnist/results:/workspace/mnist/results
      # - ./mnist/data:/workspace/mnist/data
      # - ./mnist/model:/workspace/mnist/model
      # - ./mnist/results:/workspace/mnist/results
    command: python infer.py

  #   # Build the inference service
  #   # ...

  #   # Mount volumes
  #   # ...

  #   # Run the inference command
  #   # command: python infer.py

volumes:
  mnist:

